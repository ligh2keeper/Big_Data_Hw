{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3547cce6-e493-4aeb-9b40-bf74a7471ca1",
   "metadata": {},
   "source": [
    "Подключаемся к созданному кластеру:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a128d293-0370-4fe2-88ad-393ed157c720",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "939aca27-b08a-49b4-8841-58e2b2a880db",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = pyspark.SparkContext(master=\"spark://lightkeeper:7077\",\n",
    "                          appName='spark_hw').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1467a46-4f4f-4e27-9943-a897d79d99bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.7:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://lightkeeper:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>spark_hw</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=spark://lightkeeper:7077 appName=spark_hw>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61f02733-d43c-4008-b347-0345b7cb5f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d1c9e4d-db1e-4172-b8bc-d97b7c03d076",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3fc13765-0316-45a2-a0f7-8c04a651280f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.7:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://lightkeeper:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>spark_hw</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7facd82da790>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "e8ede0f6-cf20-4f2b-9ab5-a6f4baced9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType, FloatType, StringType, StructField, StructType, TimestampType\n",
    "from pyspark.sql.functions import avg,max,count, desc, udf,\\\n",
    "col, concat_ws, unix_timestamp, from_unixtime, lit, window, monotonically_increasing_id, first\n",
    "import math\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de511778-6ba8-4c3d-8bf3-ff85e4e098f2",
   "metadata": {},
   "source": [
    "## Блок 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a0dfe4d-cc37-4c04-a259-7e71c445f557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\t\t     book1400k-1500k.csv  book4000k-5000k.csv\n",
      "..\t\t     book1500k-1600k.csv  book400k-500k.csv\n",
      "all_books_csv\t     book1600k-1700k.csv  book500k-600k.csv\n",
      "all_books.parquet    book1700k-1800k.csv  book600k-700k.csv\n",
      "book1000k-1100k.csv  book1800k-1900k.csv  book700k-800k.csv\n",
      "book100k-200k.csv    book1900k-2000k.csv  book800k-900k.csv\n",
      "book1100k-1200k.csv  book2000k-3000k.csv  book900k-1000k.csv\n",
      "book1-100k.csv\t     book200k-300k.csv\t  rating_out\n",
      "book1200k-1300k.csv  book3000k-4000k.csv  tmp\n",
      "book1300k-1400k.csv  book300k-400k.csv\t  user_rating\n"
     ]
    }
   ],
   "source": [
    "! ls -a archive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c608836c-582a-4a7f-8517-befe8ed6c855",
   "metadata": {},
   "source": [
    "### 2.1 Преобразовать данные исходного датасета в parquet объединяя все таблицы. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef33a08f-0e5e-4df7-b635-2b84d6aa4f6a",
   "metadata": {},
   "source": [
    "Сформируем датафрейм, объединив вче файлы, при этом учитываем, что в разных файлах может быть различное число полей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "71538213-cd0f-4bb5-889f-57ac3d4c9e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_path = glob.glob('archive/book*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "a5b76cb3-b0b4-4ad2-bec9-55411d4662d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.option('header', 'true').option('inferSchema', 'true')\\\n",
    "                                        .option(\"multiLine\", 'true')\\\n",
    "                                        .option(\"escape\", \"\\\"\")\\\n",
    "                                        .csv(files_path[0])\n",
    "\n",
    "for path in files_path[1:]:\n",
    "    df_2 = spark.read.option('header', 'true').option('inferSchema', 'true')\\\n",
    "                                              .option(\"multiLine\", 'true')\\\n",
    "                                              .option(\"escape\", \"\\\"\")\\\n",
    "                                              .csv(path)\n",
    "    df = df.unionByName(df_2, allowMissingColumns=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "5558841d-dd27-4cbd-966b-b2d343ec9e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Id: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Authors: string (nullable = true)\n",
      " |-- ISBN: string (nullable = true)\n",
      " |-- Rating: double (nullable = true)\n",
      " |-- PublishYear: integer (nullable = true)\n",
      " |-- PublishMonth: integer (nullable = true)\n",
      " |-- PublishDay: integer (nullable = true)\n",
      " |-- Publisher: string (nullable = true)\n",
      " |-- RatingDist5: string (nullable = true)\n",
      " |-- RatingDist4: string (nullable = true)\n",
      " |-- RatingDist3: string (nullable = true)\n",
      " |-- RatingDist2: string (nullable = true)\n",
      " |-- RatingDist1: string (nullable = true)\n",
      " |-- RatingDistTotal: string (nullable = true)\n",
      " |-- CountsOfReview: integer (nullable = true)\n",
      " |-- Language: string (nullable = true)\n",
      " |-- pagesNumber: integer (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Count of text reviews: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98070c7-3873-41c6-ab1e-8c363f1f0b94",
   "metadata": {},
   "source": [
    "Сохраним полученный датафрейм в виде parquet и csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b31330-0679-4676-9c22-8590f627d0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.mode(\"overwrite\").parquet(\"archive/all_books.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d735dd48-461d-4e02-a0d0-863b932028cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.option(\"header\", 'true').csv(\"archive/all_books_csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16344283-f885-49f7-b074-41a5313c02da",
   "metadata": {},
   "source": [
    "Сравним время чтения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "id": "87667cc2-e8bc-4bf9-8f21-40ada9efd90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 3.12 ms, total: 3.12 ms\n",
      "Wall time: 166 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "parqDF = spark.read.parquet(\"archive/all_books.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "d5580ce3-1843-44e0-a7f2-5df02494be7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.01 ms, sys: 0 ns, total: 6.01 ms\n",
      "Wall time: 366 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "csvDF = spark.read.option('header', 'true').option('inferSchema', 'true')\\\n",
    "                                        .option(\"multiLine\", 'true')\\\n",
    "                                        .option(\"escape\", \"\\\"\")\\\n",
    "                                        .csv(\"archive/all_books_csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f7563a-bf68-455b-9f29-8a0a8834a458",
   "metadata": {},
   "source": [
    "Сравним объёмы занимаемой памяти:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "3d5a4c58-fb6b-4e18-b0d5-e68ff1c670a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,2G\t./archive/all_books_csv\n"
     ]
    }
   ],
   "source": [
    "!du -sh ./archive/all_books_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "5caa54ac-c7d9-4033-ab57-de1e82b8f2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "775M\t./archive/all_books.parquet\n"
     ]
    }
   ],
   "source": [
    "!du -sh ./archive/all_books.parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf92afe-f835-4663-8a68-307ac6e6f57a",
   "metadata": {},
   "source": [
    "Делвем вывод, что формат parquet выигрывает по скорости чтения перед csv, а также занимает в 1.5 разаменьше памяти."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b9a2f4-4d88-4a43-9459-c244e9b3714c",
   "metadata": {},
   "source": [
    "### 2.2 Используя весь набор данных с помощью Spark вывести"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73adb52b-f81e-45e3-9f3c-7fcf202a6eca",
   "metadata": {},
   "source": [
    "#### а) Топ-10 книг с наибольшим числом ревью"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0d85ba0-08ac-471d-9f1c-303465f84385",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+\n",
      "|                Name|CountsOfReview|\n",
      "+--------------------+--------------+\n",
      "|The Hunger Games ...|        154447|\n",
      "|Twilight (Twiligh...|         94850|\n",
      "|      The Book Thief|         87685|\n",
      "|            The Help|         76040|\n",
      "|Harry Potter and ...|         75911|\n",
      "|The Giver (The Gi...|         57034|\n",
      "| Water for Elephants|         52918|\n",
      "|The Girl with the...|         52225|\n",
      "|Harry Potter and ...|         52088|\n",
      "|The Lightning Thi...|         48630|\n",
      "+--------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.orderBy(col(\"CountsOfReview\").desc())\\\n",
    "  .select(\"Name\", \"CountsOfReview\")\\\n",
    "  .limit(10).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42531e7-169b-4703-8262-80112749ea2c",
   "metadata": {},
   "source": [
    "#### b) Топ-10 издателей с наибольшим средним числом страниц в книгах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7394462-4fd7-4cbf-9c31-94f6b0a4ce7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 47:===================================================>    (21 + 2) / 23]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|           Publisher|          avg_page|\n",
      "+--------------------+------------------+\n",
      "|Crafty Secrets Pu...|         1807321.6|\n",
      "|    Sacred-texts.com|          500000.0|\n",
      "|Department of Rus...| 322128.5714285714|\n",
      "|Logos Research Sy...|          100000.0|\n",
      "|Encyclopedia Brit...|           32642.0|\n",
      "|Progressive Manag...|        19106.3625|\n",
      "|Still Waters Revi...|10080.142857142857|\n",
      "|P. Shalom Publica...|            8539.0|\n",
      "|Hendrickson Publi...|            6448.0|\n",
      "|            IEEE/EMB|            6000.0|\n",
      "+--------------------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"Publisher\")\\\n",
    "  .agg(avg(\"pagesNumber\").alias(\"avg_page\"))\\\n",
    "  .sort(desc(\"avg_page\"))\\\n",
    "  .limit(10).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e4099d-6a90-4ba1-a7ae-e6b4e6d0cdf9",
   "metadata": {},
   "source": [
    "#### c) Десять наиболее активных по числу изданных книг лет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "683fe457-136e-4d4a-80f3-18ec43298406",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 50:=====================================================>  (22 + 1) / 23]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+\n",
      "|PublishYear|n_books|\n",
      "+-----------+-------+\n",
      "|       2007| 129507|\n",
      "|       2006| 122374|\n",
      "|       2005| 117639|\n",
      "|       2004| 105733|\n",
      "|       2003| 104345|\n",
      "|       2002|  95537|\n",
      "|       2001|  88228|\n",
      "|       2000|  87290|\n",
      "|       2008|  80265|\n",
      "|       1999|  80155|\n",
      "+-----------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"PublishYear\")\\\n",
    "  .agg(count(\"*\").alias(\"n_books\"))\\\n",
    "  .sort(desc(\"n_books\"))\\\n",
    "  .limit(10).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8a2107-3a64-4e58-bf0d-0239edf29e5c",
   "metadata": {},
   "source": [
    "#### d) Топ-10 книг имеющих наибольший разброс в оценках среди книг имеющих больше 500 оценок"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cada2992-0104-4963-91c6-51a1737f6062",
   "metadata": {},
   "source": [
    "Сначала очистим значения полей рейтинг, отавив только значения после \":\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09ef0af8-790b-42e1-9a70-ea97f1860eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_ratings = udf(lambda s: s.split(':')[1], StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3676de2-3dc6-4a66-90c4-0b80634bfa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('RatingDistTotal', clean_ratings(df.RatingDistTotal))\\\n",
    "         .withColumn('RatingDist1', clean_ratings(df.RatingDist1))\\\n",
    "         .withColumn('RatingDist2', clean_ratings(df.RatingDist2))\\\n",
    "         .withColumn('RatingDist3', clean_ratings(df.RatingDist3))\\\n",
    "         .withColumn('RatingDist4', clean_ratings(df.RatingDist4))\\\n",
    "         .withColumn('RatingDist5', clean_ratings(df.RatingDist5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8d4fe2-8dd1-4663-9849-6885c007de15",
   "metadata": {},
   "source": [
    "Напишем функцию, вычисляющую стандртное отклонение для оценок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c141e3d8-fbbc-4c5e-8756-25d1afc828df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_std(ratings):\n",
    "    ratings = list(map(float, ratings.split()))\n",
    "    total = ratings[0]\n",
    "    rating = ratings[1:]\n",
    "    mean =  sum([(i+1)*x for i, x in enumerate(rating)]) / total\n",
    "    std = math.sqrt(sum([x*(i + 1 - mean)**2 for i, x in enumerate(rating)]) / total)\n",
    "    return std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a984442-2fdc-4aac-9bcd-7646106bb3f8",
   "metadata": {},
   "source": [
    "Образуем новую колонку для стандартного отклонения посчитав его для кажой строки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "732afdf5-f09d-400d-9729-7e1bf7f10192",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_std = udf(calculate_std, FloatType())\n",
    "\n",
    "df = df.withColumn('std', get_std(concat_ws(\" \", col(\"RatingDistTotal\"),\n",
    "                                                col(\"RatingDist1\"), \n",
    "                                                col(\"RatingDist2\"), \n",
    "                                                col(\"RatingDist3\"), \n",
    "                                                col(\"RatingDist4\"), \n",
    "                                                col(\"RatingDist5\"))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c666f4d-cc5b-4c47-8aa9-b20b529fe88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 53:=====================================================>  (22 + 1) / 23]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+---------+---------------+\n",
      "|     Id|                Name|      std|RatingDistTotal|\n",
      "+-------+--------------------+---------+---------------+\n",
      "|2247237|Scientology: The ...|1.6768911|            853|\n",
      "| 564449|Scientology: The ...|1.6754147|            838|\n",
      "|2355709|Para Entrenar a u...|1.6598984|           1656|\n",
      "| 675331| To Train Up a Child|1.6595358|           1636|\n",
      "| 214280|Para Entrenar a u...|1.6594893|           1634|\n",
      "|2175673|The Bluebook: A U...|1.5883198|            542|\n",
      "|2238150|The Bluebook: A U...|1.5883198|            542|\n",
      "|4573714|Dianetics: The Mo...|1.5621103|           2897|\n",
      "|3036308|Dianetics: The Mo...|1.5608956|           2869|\n",
      "|2724205|Dianetica: La Cie...|1.5603579|           2860|\n",
      "+-------+--------------------+---------+---------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.filter(col(\"RatingDistTotal\") > 500)\\\n",
    "  .orderBy(col(\"std\").desc())\\\n",
    "  .select(\"Id\", \"Name\", \"std\", \"RatingDistTotal\")\\\n",
    "  .limit(10).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885dc1aa-e016-40ca-8fdc-c04305db77ec",
   "metadata": {},
   "source": [
    "#### e) Любой интересный инсайт из данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fcf848-ef7b-4ee1-af56-45d25eb4646b",
   "metadata": {},
   "source": [
    "Если посчитать наиболее активный по числу изданных книг месяц, то окажется что больше всего книг издаётся в конце и начале года. Единственное, в полученном датафрейме количество уникальных значений для значения месяца не 12, а 31. Это связано с тем, что в некоторых исходных таблицах перепутаны значения колонок месяц и день."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef709ed0-3253-4be4-a306-bc1616cfdf0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 54:=====================================================>  (22 + 1) / 23]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------+\n",
      "|PublishMonth|n_books|\n",
      "+------------+-------+\n",
      "|           1| 589982|\n",
      "|          12| 125327|\n",
      "|           9|  95739|\n",
      "|          10|  93673|\n",
      "|           3|  90724|\n",
      "|           6|  84709|\n",
      "|           4|  83594|\n",
      "|           5|  82201|\n",
      "|           8|  79038|\n",
      "|          11|  77834|\n",
      "|           2|  75004|\n",
      "|           7|  74494|\n",
      "|          15|  36284|\n",
      "|          31|  25949|\n",
      "|          28|  22265|\n",
      "|          30|  22095|\n",
      "|          17|  16884|\n",
      "|          25|  15498|\n",
      "|          20|  13648|\n",
      "|          27|  13414|\n",
      "+------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"PublishMonth\")\\\n",
    "  .agg(count(\"*\").alias(\"n_books\"))\\\n",
    "  .sort(desc(\"n_books\"))\\\n",
    "  .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcff535-8982-44bd-8c12-2dd6bd816e84",
   "metadata": {},
   "source": [
    "## Блок 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4657eebc-08a2-4c73-88e4-80ce8ff4f1ca",
   "metadata": {},
   "source": [
    "Посмотрим сначала на структуру датасета, в нём всего три поля:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "d1d85c11-190e-4308-a9ca-3af96b067dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"archive/user_rating/*\", header=True, inferSchema=True, multiLine=True, escape=\"\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "f6c3791f-f2ad-448f-a206-37a7f2d65f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Rating: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cd04ef-f8ad-4186-88fa-4c2cabfbd1ea",
   "metadata": {},
   "source": [
    "Чтобы вычислить средний рейтинг нам нужно преобразовать строковое описание рейтинга в число, для этого посмотрим какие уникальные значения может принимть поле рейтинг:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "7ce7f785-5d36-4760-ae02-eea7b9aad30e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|              Rating|\n",
      "+--------------------+\n",
      "|     did not like it|\n",
      "|     really liked it|\n",
      "|            liked it|\n",
      "|           it was ok|\n",
      "|      it was amazing|\n",
      "|This user doesn't...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"Rating\").distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b144d9-622d-45e7-8248-e272a9b25a29",
   "metadata": {},
   "source": [
    "Зададим для этих значений словарь соответсвия:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "000c17ff-6e41-49d2-a794-6b5677bff62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_int = {\n",
    "    \"did not like it\": 1,\n",
    "    \"it was ok\": 2,\n",
    "    \"liked it\": 3,\n",
    "    \"really liked it\": 4,\n",
    "    \"it was amazing\": 5,\n",
    "    \"This user doesn't have any rating\": -1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "44fb1327-bcc3-4dc3-8704-96cf70fd94c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_to_int = udf(lambda s: rating_int[s], IntegerType())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50894672-ea44-45f4-b44c-9ed61cc81fc7",
   "metadata": {},
   "source": [
    "Задаём схему данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "d0141895-6f14-4676-8d1a-99d547349288",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSchema = StructType([\n",
    "    StructField(\"Id\", IntegerType(),True),\n",
    "    StructField(\"Name\", StringType(),True),\n",
    "    StructField(\"Rating\", StringType(),True)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9387a2-21cd-4f07-b429-cbd1ccc3be6b",
   "metadata": {},
   "source": [
    "Задаём file source:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "c65ca0b3-bfc8-4fc7-a9ed-d540002654bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "streaming = (\n",
    "    spark.readStream.schema(dataSchema)\n",
    "    .csv(\"archive/user_rating/\", header=True, inferSchema=True, multiLine=True, escape=\"\\\"\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd97494b-0e74-4dd8-b11e-4a6f7640eed2",
   "metadata": {},
   "source": [
    "Задаём преобразование данных. Сначала переводим рейтинг в числовое значение, затем вычисляем среднее значение группируя по названию книги:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "id": "0ebb8c1a-5611-4fcd-9bce-75528a5bc38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dest_df = streaming.withColumn(\"Rating\", rating_to_int(col(\"Rating\")))\\\n",
    "                   .groupBy(col(\"Name\")) \\\n",
    "                   .agg(avg(\"Rating\").alias(\"avg_rating\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11d73e5-50d4-4dc6-802a-08f5bf0ef6af",
   "metadata": {},
   "source": [
    "Задаём sink:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "b11081f2-7599-4105-808f-683ba0e7b3de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/08 05:06:33 WARN ResolveWriteToStream: Temporary checkpoint location created which is deleted normally when the query didn't fail: /tmp/temporary-e5bede83-0b02-44af-80f8-4c6d27e4b21d. If it's required to delete it under any circumstances, please set spark.sql.streaming.forceDeleteTempCheckpointLocation to true. Important to know deleting temp checkpoint folder is best effort.\n",
      "23/10/08 05:06:33 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "query = (\n",
    "    dest_df.writeStream.queryName(\"avg_rating_df\")\n",
    "    .format(\"memory\")\n",
    "    .outputMode(\"update\")\n",
    "    .start()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "458e45b6-2154-4e12-8239-138eb9f643f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.streams.active[0].isActive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "id": "33f43b40-8c52-415c-834a-d02281c34f66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': 'Waiting for data to arrive',\n",
       " 'isDataAvailable': False,\n",
       " 'isTriggerActive': False}"
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "id": "3d2cc98b-6107-481a-8444-f153d92fda28",
   "metadata": {},
   "outputs": [],
   "source": [
    "query.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffcff8f-602f-47bd-a2c3-2dbfa4c32e33",
   "metadata": {},
   "source": [
    "Сравним результат полученный через straming и без него:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "be4d9351-6634-4a3c-a209-fbf1b141ccc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|                Name|        avg_rating|\n",
      "+--------------------+------------------+\n",
      "|     !آنچه سینما هست|               2.0|\n",
      "|!از قر و قمبیل‌ها...|               5.0|\n",
      "|   \" Talking Heads \"|               2.0|\n",
      "|\"A Problem from H...|               4.0|\n",
      "|   \"A\" Is for Africa|               3.0|\n",
      "|\"A\" is for Apple ...|               3.0|\n",
      "|    \"B\" Is for Betsy|               5.0|\n",
      "|\"Beat\" Takeshi Ki...|               5.0|\n",
      "|\"C\" Is For Corpse...|               3.0|\n",
      "|   \"Cinema Paradiso\"|               5.0|\n",
      "|\"Do you consider ...|               2.0|\n",
      "|        \"Giant\" Size|               4.0|\n",
      "|\"Headhunter\" Hiri...|               2.0|\n",
      "|\"I Am a Man\": Chi...|               3.0|\n",
      "|\"Love, Loss and L...|               5.0|\n",
      "|\"Master Harold\".....|               3.5|\n",
      "|            \"Mayday\"|               5.0|\n",
      "|\"Membumikan\" Al-Q...|2.6666666666666665|\n",
      "|\"Multiplication I...|               3.0|\n",
      "|\"My Teenage Son's...|               4.0|\n",
      "+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/08 05:10:02 WARN TaskSetManager: Stage 683 contains a task of very large size (2068 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    }
   ],
   "source": [
    "spark.sql('SELECT * from avg_rating_df').orderBy(\"Name\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "a4d8de77-0709-406c-95d4-2b2690703a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 657:==============>                                          (1 + 3) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|                Name|        avg_rating|\n",
      "+--------------------+------------------+\n",
      "|     !آنچه سینما هست|               2.0|\n",
      "|!از قر و قمبیل‌ها...|               5.0|\n",
      "|   \" Talking Heads \"|               2.0|\n",
      "|\"A Problem from H...|               4.0|\n",
      "|   \"A\" Is for Africa|               3.0|\n",
      "|\"A\" is for Apple ...|               3.0|\n",
      "|    \"B\" Is for Betsy|               5.0|\n",
      "|\"Beat\" Takeshi Ki...|               5.0|\n",
      "|\"C\" Is For Corpse...|               3.0|\n",
      "|   \"Cinema Paradiso\"|               5.0|\n",
      "|\"Do you consider ...|               2.0|\n",
      "|        \"Giant\" Size|               4.0|\n",
      "|\"Headhunter\" Hiri...|               2.0|\n",
      "|\"I Am a Man\": Chi...|               3.0|\n",
      "|\"Love, Loss and L...|               5.0|\n",
      "|\"Master Harold\".....|               3.5|\n",
      "|            \"Mayday\"|               5.0|\n",
      "|\"Membumikan\" Al-Q...|2.6666666666666665|\n",
      "|\"Multiplication I...|               3.0|\n",
      "|\"My Teenage Son's...|               4.0|\n",
      "+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"Rating\", rating_to_int(col(\"Rating\")))\\\n",
    "                   .groupBy(col(\"Name\")) \\\n",
    "                   .agg(avg(\"Rating\").alias(\"avg_rating\")).orderBy(\"Name\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315a6024-4b3b-465d-852e-3df9a23852ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
